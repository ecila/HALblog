---
layout: post
#
# Content
#
subheadline: "Reflections on workshop 1"
title: "What (experimental media) design could do for humanising algorithmic listening"
teaser: "In search for a common field of problems"
categories:
  - Reflections
tags:
  - info
author: shintaro_miyazaki
show_meta: true
comments: true
date: 2017-05-04
#
# Styling
#
header: no
image:
    title: shintaro_Jolly_w1.jpg
    thumb: shintaro_Jolly_w1.jpg
    homepage: shintaro_Jolly_w1.jpg
mediaplayer: true
---

Disclaimer: Please read the following keeping in mind that I am not trained in signal processing, data mining nor have an engineering background. The concepts I use need complementation by more knowledgeable persons.

I decided to write up my thoughts right after the great first workshop (which I really enjoyed) and before they fade away. Hopefully I can clarify some of my arguments here; perhaps we can also begin to sketch some common fields of problems for all network participants. As a media archaeologist turned non-affirmative design researcher with a background in improvised laptop music I might care at least for some of the overlapping fields. My remarks resonate mostly with the aspect of [„Unpacking black boxes through listening“](http://www.algorithmiclistening.org/introductions/distantlistening/) Alice  sketched out in her introductory blog post.

![stethoscope](https://upload.wikimedia.org/wikipedia/commons/6/6d/Standardized-Patient-Program-examining-t_he-abdomen.jpg){:width="100%"}   *Standardized Patient Program examining the abdomen, Photo by Steve Perrin CC BY 2.0*


Historically considered, listening has been a crucial method of unpacking boxes or enclosed bodies even before literally unpacking it, but by trying to listen to the sounds coming from inside the body both passively with a listening device or even actively by gently knocking it. You can do this with a variety of artifacts, products and found things such as stones, water melons, cheese, earth grounds, human bodies, cars and of course with all sorts of percussive instruments. In all these examples there is a tight coupling between the sound created and the characteristics and structure of the body under inquiry. Since the dawn of transducers such as the telephone in the late 1870s, we can listen into electrical signals such as those of muscles or nerves, and at the same time transform electrical signals into sound. And with the dawn of the vacuum tube amplification in the 1910s, we can amplify tiny signals, such as those of brain neurons.

Following the links Alice posted and through some of the more informal discussions I had during the workshop I guess that **filtering** is a key aspect of machine or algorithmic listening. Filtering here is not only meant in a more metaphorical meaning as a way to structure incoming data and materia (thus as a common element to all data analysis) but  literally, thus more media archaeologically, as procedures in signal processing. The digitalisation and quantification of analog electroacoustic signals into digital data for example is some sort of filtering, also the hand-crafted filtering of essential structures in audio feature extraction, which is, as I learned during the workshop, the first step of algorithm-based audio analysis (aka machine listening). before filtering them further with classification, regression and other algorithms as done in data mining and [machine learning](https://en.wikipedia.org/wiki/Machine_learning). This „hand-crafted“ and skilled practice for me is of peculiar interest and certainly for a research network that wants to „humanise“ algorithmic listening. Practices of filtering could form a research field to get worked through with a combination of ethnographic/STS, historical and practice-based methods.

*Who decides how, when and why about the value of a certain feature and what kind of media and [cultural techniques](https://monoskop.org/Cultural_techniques) (visualization, drawing, singing, computing) are involved in the practices of hand-crafted audio feature extraction? Are there aesthetic and [designerly](http://oro.open.ac.uk/39253/) decisions? What are the [protocols](https://mitpress.mit.edu/books/protocol) within such a field of practice?* Unboxing and unpacking machine or algorithmic listening means for me to critically inquire each step, each of its module in the pipe line of [feature extraction, classification, segmentation and visualization](https://github.com/tyiannak/pyAudioAnalysis/wiki). Sonification, audification and visualization of the filtering steps, processes and results are then also helpful in unboxing the more advanced data-driven feature extractors using neural networks as done by PhD Student at Queen Mary University of London,[Keunwoo Choi](https://keunwoochoi.wordpress.com/2016/03/23/what-cnns-see-when-cnns-see-spectrograms/).

*Is there space for design-based experimentation for example in varying the modes of visualization or for auralisation/ audification? Can we listen to the algorithms filtering the data as sonification, not of the data but of the processes that generate data? Can we design human interfaces for the modules in the data analysis pipeline? Would that be helpful for getting a more comprehensive and critical understanding of machinic listening? Can we [diffract](http://newmaterialism.eu/almanac/d/diffraction) algorithmic listening? Who are the data workers and researchers involved in algorithmic listening? What is the „sayable and the visible“ (Foucault) of algorithmic listening and how could we change it by design? What kind of effects would historical contextualization have on that process?* The history of resistor–capacitor circuits and filters is for example strongly connected to [telegraphy](https://en.wikipedia.org/wiki/Telegrapher%27s_equations). In context of underwater warfare during WW2 and later operating on different audio filters was a crucial [skill for sonar operators](https://maritime.org/doc/fleetsub/sonar/chap4.htm#4A).

Hopefully my impulse caused some response ...   
Please write some of your thoughts in the comments section.
