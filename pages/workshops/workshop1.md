---
layout: page
title: "Workshop 1"
header: no
image:
  title: "grays_lato_img.gif"

permalink: "/workshop1/"
---



### Interdisciplinary perspectives: Deep & Distant Listening
April 27-28. Sussex Humanities Lab, University of Sussex, Brighton

[[ jump to: [SCHEDULE](#schedule) ...  [SPEAKERS](#speakers) ... [LOCATION](#location) ]]

The network provides a unique opportunity to curate a conversation across disciplines, and to provoke broad imaginings around the implications of and possibilities for machine listening in research and practice, as well as in our daily lives.

The first workshop aims to lay the foundations for an interdisciplinary research agenda by bringing together researchers and practitioners from history, archive services, philosophy, media archeology, sound arts, computer science and computer music to share archival, technical and critical perspectives on algorithmic listening.

On day 1 core participants from history, archives, computer science, computer music, cultural studies and philosophy will give short presentations to stimulate an initial mapping out of future research agenda. Following the round table on day 2, participants will work together in groups to consider the sorts of questions machine listening might open up in humanities research. Teams will be armed with python notebooks loaded with relevant machine listening and learning libraries. The winning idea will be submitted to online data science community, Kaggle.

All discussions will be mediated and documented by human and machine listeners.


We will consider questions such as:
* *What are the challenges and opportunities of working with large digital audio databases for humanities researchers, sound artists and archivists?*
* *How is machine listening being applied in other areas of research and practice and what can we learn from this?*
* *What are the cultural, epistemological or phenomenological implications of technologically mediated listening?*
* *How can ideas from the history of philosophy of technology be applied to productively shape ethical and technical designs in the future?*

----
## <a name="schedule"></a> SCHEDULE
----

### Day 1 Presentations & discussion

*Draft timetable: (subject to change)*

+ 10:30 : Coffee
+ 11:00 : Welcome
+ 11:30 : Presentations: Practical & Technical
+ 13:00 : lunch
+ 14:00 : Presentations: Critical & Philosophical
+ 15:30 : Coffee Break & Feedback Cello Installation
+ 16:15 : Break out group discussions - agenda brainstorming
+ 18.15 : Fin

Dinner in Brighton


### Day 2 - Kaggle challenge

*Draft time table -- subject to change*
+ 09:30 : Coffee
+ 10:00 : Round Table - initial agenda scoping
+ 12:30 : Kaggle briefing and team formation
+ 13:00 : Lunch Break
+ 14:00 : Kaggle challenge brain storming
+ 15:30 : Coffee & tea break
+ 16:00 : Kaggle team presentations & vote
+ 17:00 : Roundtable discussion and summary of the day
+ 18.00 : Fin

----

## <a name="speakers"></a>  SPEAKERS
----
### Ron Chrisley -
### Tristan Clutterbuck -
### Fiona Courage -
### Steven Dorrestijn -
### Beatrice Fazi -

### Tim Hitchcock - *Listening to the Dead*
![TM](p_hitchcock15.jpg)

The traces of the past historians normally rely upon are made up of rotting print and fragile manuscript.  But a proportion of this material represents speech uttered in known environments – courtrooms, churches and parliamentary chambers.  And as these traces of the dead have been digitised and turned in to a new kind of 'object of study' (searchable, mash-upable, and macroscopable) we are increasingly challenged to analyse them in light of all the other forms of data that intersect with mere textual recordings   This presentation briefly suggest that the addition of a quantifiable understanding of sound (reflecting historical spaces and environments) to a ‘big data’ approach to textual representations of historical speech, allows us to understand the meaning and import of that speech (and inherited text) in a fundamentally new way.  It allows to listen to the dead, in hopes of hearing the timbre and rhythms of their words.

Tim Hitchcock is Professor of Digital History at the University of Sussex, and co-director of the Sussex Humanities Lab.  A historian of eighteenth and nineteenth century London, Hitchcock has published widely on poverty, sexuality and crime.  With Robert Shoemaker, he has also been responsible for half a dozen major web resources making searchable and re-usable some 35 billion words of historical text and several hundred thousand images.   

### Chris Kiefer -
### Parag Mital -
### Shintaro Miyazaki -

### Sally-Jane Norman - *Tuning (with/ to/ by) Exosomatic Organs*
![SJN](/p_sjn.jpg)

The Old English term *hlysnan* designates listening, hearing, and paying attention, and musicking history abounds in technical artefacts designed to extend our listening abilities. These exosomatic organs (Robert Innis) augment human expressivity, soliciting their creative users and audiences by employing and deploying algorithmic functions – sets of rules or processes. Drawing on music history, I will argue that cultural tuning is key to humanising emerging algorithmic listening practices.

Sally-Jane Norman is Professor of Performance Technologies and Co-Director of Sussex Humanities Lab where she leads the  ‘Digital Technologies, Digital Performance’ strand. She joined Sussex after serving as founding Director of Culture Lab at Newcastle University, Research Director at the Institut International de la Marionnette (Charleville-Mézières), and Artistic Co-Director of STEIM (co-organiser of the first Touch Festival with Michel Waisvisz and Joel Ryan). She is a dual citizen of Aotearoa/ New Zealand and France, trandisciplinary performance scholar (Doctorat d’état, Paris III) and sometime practitioner.  From July, Sally Jane will become Director of Te Koki - New Zealand School of Music, at Victoria University in Wellington, Aotearoa.


### Dan Stowell - *Computers Listening to Birds*
![DS](https://github.com/ecila/HALblog/blob/gh-pages/images/p_danStowell.jpeg)

The sounds that birds make are a fascinating challenge for algorithmic listening. Often there is evidence of much complexity, yet how little we understand about the content and purpose of each individual sound. (Whereas with human sounds, we fool ourselves into thinking that we do understand the content and purpose.) I will outline the ways in which we have developed machine listening methods adapted to specific aspects of bird vocalisation - its fine details and its temporal structure - and how the challenge relates to the wider field of machine listening.

Dan Stowell is a researcher in machine listening - which means using computation to understand sound signals. He co-leads the Machine Listening Lab at Queen Mary University of London, based in the Centre for Digital Music. Dan has worked on voice, music and environmental soundscapes, and is currently leading a five-year EPSRC fellowship project researching the automatic analysis of bird sounds. His first degree was from Cambridge University, and his PhD from Queen Mary University of London.



----

## <a name="location"></a>  LOCATION and DIRECTIONS
----

Sussex Humanities Lab, Silverstone SB211, Arts Road, Falmer, East Sussex, BN1 9RG

We are a short bus or train journey from the centre of Brighton and within easy reach of London via the Victoria and Thameslink lines and the major international airports at Gatwick and Heathrow.

Travel Directions can be found [here](http://www.sussex.ac.uk/about/directions)

The Sussex Humanities Lab is located in the School of Media, Film & Music, Silverstone Building which is situated in Arts Road, between Arts blocks B and C (number '16' on the [campus map](www.sussex.ac.uk/about/documents/campusmap.pdf)).

Participant accommodation is in central Brighton at the [Premiere Inn](http://www.premierinn.com/gb/en/hotels/england/east-sussex/brighton/brighton-city-centre.html). 144 North Street, Brighton, East Sussex BN1 1RE
