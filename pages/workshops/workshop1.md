---
layout: page
title: "Workshop 1"
header: no
image:
  title: "grays_lato_img.gif"

permalink: "/workshop1/"
---



### Interdisciplinary perspectives: Deep & Distant Listening
April 27-28. Sussex Humanities Lab, University of Sussex, Brighton

[[ jump to: [SCHEDULE](#schedule) ...  [SPEAKERS](#speakers) ... [LOCATION](#location) ]]

The network provides a unique opportunity to curate a conversation across disciplines, and to provoke broad imaginings around the implications of and possibilities for machine listening in research and practice, as well as in our daily lives.

The first workshop aims to lay the foundations for an interdisciplinary research agenda by bringing together researchers and practitioners from history, archive services, philosophy, media archeology, sound arts, computer science and computer music to share archival, technical and critical perspectives on algorithmic listening.

On day 1 core participants from history, archives, computer science, computer music, cultural studies and philosophy will give short presentations to stimulate an initial mapping out of future research agenda. Following the round table on day 2, participants will work together in groups to consider the sorts of questions machine listening might open up in humanities research. Teams will be armed with python notebooks loaded with relevant machine listening and learning libraries. The winning idea will be submitted to online data science community, Kaggle.

All discussions will be mediated and documented by human and machine listeners.


We will consider questions such as:
* *What are the challenges and opportunities of working with large digital audio databases for humanities researchers, sound artists and archivists?*
* *How is machine listening being applied in other areas of research and practice and what can we learn from this?*
* *What are the cultural, epistemological or phenomenological implications of technologically mediated listening?*
* *How can ideas from the history of philosophy of technology be applied to productively shape ethical and technical designs in the future?*

----
## <a name="schedule"></a> SCHEDULE
----

### Day 1 Presentations & discussion

+ 10:30 : Coffee
+ 11:00 : Welcome
+ 11:30 : Presentations: Practical & Technical
+ 13:00 : lunch
+ 14:00 : Presentations: Critical & Philosophical
+ 15:30 : Coffee Break & Feedback Cello Installation
+ 16:15 : Break out group discussions - agenda brainstorming
+ 18.15 : Fin

Dinner in Brighton


### Day 2 - Kaggle challenge


+ 09:30 : Coffee
+ 10:00 : Round Table - initial agenda scoping
+ 12:30 : Kaggle briefing and team formation
+ 13:00 : Lunch Break
+ 14:00 : Kaggle challenge brain storming
+ 15:30 : Coffee & tea break
+ 16:00 : Kaggle team presentations & vote
+ 17:00 : Roundtable discussion and summary of the day
+ 18.00 : Fin

----

## <a name="speakers"></a>  SPEAKERS
----
### Ron Chrisley -
<p></p>
<p></p>
----
### Tristan Clutterbuck -
<p></p>
<p></p>
----
### Fiona Courage -
<p></p>
<p></p>
----
![image of Steven Dorrestijn]({{site.urlimg}}p_Dorrestijn.jpg)
### Steven Dorrestijn - *Being heard and remembered: Technical mediation and what it means to be human*
The technical mediation approach in the philosophy of technology considers that technology is more than just an external factor that can support and hinder human life. Technology is constitutive for human self-understanding and for what it means to be human. What does this mean for an ethics of technology? Must we learn to take care of our hybrid selves? For this occasion, I will especially refer to the impact of recording and transporting speech.


Steven Dorrestijn is a senior researcher in the Ethics and Technology research group at Saxion University of Applied Sciences, the Netherlands. Dorrestijn’s research and publications focus on the philosophy and ethics of technology. He has a broad, cross-disciplinary interest in examples and conceptualizations of how technology mediates human existence. To make such insights about the impacts of technology on humans useful for the assessment and design of technologies he has develops the “Product Impact Tool”. For ethical reflection on living technically mediated lives Dorrestijn has specialized in the work of Michel Foucault and technology.
In 2012 Dorrestijn completed his PhD thesis, The design of our own lives: Technical mediation and subjectivation after Michel Foucault, at the University of Twente, the Netherlands. Previously he studied Philosophy in Paris and Philosophy and Mechanical Engineering in Twente.


<p></p>
<p></p>
----

![image of Beatrice Fazi]({{site.urlimg}}p_fazi_beatrice.jpg)
### **Beatrice Fazi** - *Listening with machines that are already ‘listening’? From Augmentation to Automation*
*What does it mean to listen with or through machines that are already ‘listening’?* I engage with this question by examining the anthropomorphism that might be implicit in the notion of ‘listening algorithms’.  This will help me to argue for the difference between functions and processes of ‘augmentation’ on the one hand, and of ‘automation’ on the other. I will argue that whilst augmentation implies the extension and exteriorisation of predefined forms or modes of behaviour, contemporary developments in computational automation ask us instead to consider the possibility to move beyond a simulative paradigm or phenomenological analogies.


Beatrice Fazi is Research Fellow in Digital Humanities & Computational Culture at the Sussex Humanities Lab (University of Sussex, United Kingdom). Her primary areas of expertise are the philosophy of computation, the philosophy of technology and the new emerging field of media philosophy. Beatrice’s current work investigates the limits and potentialities of formal reasoning in relation to computation, and aims to offer a re-conceptualisation of contingency within formal axiomatic systems vis-à-vis technoscientific notions of incompleteness and incomputability. This research is part of a monograph that she is currently writing on how indeterminacy shapes the ontological foundation of computational aesthetics.
<p></p>
<p></p>

----

![Image of Tim Hitchcock]({{site.urlimg}}p_hitchcock15.jpg)
### **Tim Hitchcock** - *Listening to the Dead*
<p></p>

The traces of the past historians normally rely upon are made up of rotting print and fragile manuscript.  But a proportion of this material represents speech uttered in known environments – courtrooms, churches and parliamentary chambers.  And as these traces of the dead have been digitised and turned in to a new kind of 'object of study' (searchable, mash-upable, and macroscopable) we are increasingly challenged to analyse them in light of all the other forms of data that intersect with mere textual recordings   This presentation briefly suggest that the addition of a quantifiable understanding of sound (reflecting historical spaces and environments) to a ‘big data’ approach to textual representations of historical speech, allows us to understand the meaning and import of that speech (and inherited text) in a fundamentally new way.  It allows to listen to the dead, in hopes of hearing the timbre and rhythms of their words.

Tim Hitchcock is Professor of Digital History at the University of Sussex, and co-director of the Sussex Humanities Lab.  A historian of eighteenth and nineteenth century London, Hitchcock has published widely on poverty, sexuality and crime.  With Robert Shoemaker, he has also been responsible for half a dozen major web resources making searchable and re-usable some 35 billion words of historical text and several hundred thousand images.   

<p></p>
<p></p>
----

### **Chris Kiefer** -

<p></p>
<p></p>
----
![Image of Parag Mital]({{site.urlimg}}p_parag.png)
### **Parag Mital** - *Auditory Perception and Attention and computational arts*

<p></p>
I will present a cursory overview of fMRI and EEG literature relating to auditory perception and attention mechanisms, behavioral science of auditory attention, and detail some computational investigations for understanding audio within a computational arts practice.

Parag K. MITAL (US) is an artist and interdisciplinary researcher obsessed with the nature of information, representation, and attention. Using film, eye-tracking, EEG, and fMRI recordings, he has worked on computational models of audiovisual perception from the perspective of both robots and humans, often revealing the disjunct between the two, through generative film experiences, augmented reality hallucinations, and expressive control of large audiovisual corpora. Through this process, he balances his scientific and arts practice, with both reflecting on each other: the science driving the theories, and the artwork re-defining the questions asked within the research. His work has been exhibited internationally including the Prix Ars Electronica, ACM Multimedia, Victoria & Albert Museum, London’s Science Museum, Oberhausen Short Film Festival, and the British Film Institute, and featured in FastCompany, BBC, NYTimes, CreativeApplications.Net, and CreateDigitalMotion.

<p></p>
<p></p>
----
![image of Shintaro Miyazaki]({{site.urlimg}}p_shintaro_IAMAS_2015.jpg)
### **Shintaro Miyazaki** - *Listening to Algorhythmics*
<p></p>

The aim is to provide a probably diametrically opposed approach to “machine listening“ via a media archaeological inquiry into algorhythmic listening in the era between 1940–1965, where mainframe machine operators and scientists were listening to their computing machinery. I will provide some further implementations for the digital humanities context.

Shintaro Miyazaki is a Berlin-born Swiss-Japanese media and design scholar and experimental media designer. He has been a Senior Researcher at the Critical Media Lab of the Institute of Experimental Design and Media Cultures, Academy of Art and Design part of the University of Applied Sciences and Arts Northwestern Switzerland in Basel since 2014 and since 2016 principle investigator there. Shintaro obtained a PhD in media theory at Humboldt-Universität in Berlin (2012). His current interests include cybernetics, design theory and research, non-visual modes of knowledge.
<p></p>
<p></p>

----
![SJN]({{site.urlimg}}p_sjn.jpg)
### **Sally-Jane Norman** - *Tuning (with/ to/ by) Exosomatic Organs*
<p></p>

The Old English term *hlysnan* designates listening, hearing, and paying attention, and musicking history abounds in technical artefacts designed to extend our listening abilities. These exosomatic organs (Robert Innis) augment human expressivity, soliciting their creative users and audiences by employing and deploying algorithmic functions – sets of rules or processes. Drawing on music history, I will argue that cultural tuning is key to humanising emerging algorithmic listening practices.

Sally-Jane Norman is Professor of Performance Technologies and Co-Director of Sussex Humanities Lab where she leads the  ‘Digital Technologies, Digital Performance’ strand. She joined Sussex after serving as founding Director of Culture Lab at Newcastle University, Research Director at the Institut International de la Marionnette (Charleville-Mézières), and Artistic Co-Director of STEIM (co-organiser of the first Touch Festival with Michel Waisvisz and Joel Ryan). She is a dual citizen of Aotearoa/ New Zealand and France, trandisciplinary performance scholar (Doctorat d’état, Paris III) and sometime practitioner.  From July, Sally Jane will become Director of Te Koki - New Zealand School of Music, at Victoria University in Wellington, Aotearoa.

<p></p>
<p></p>
----

![DS]({{site.urlimg}}p_danStowell.jpeg)
### **Dan Stowell** - *Computers Listening to Birds*
<p></p>

The sounds that birds make are a fascinating challenge for algorithmic listening. Often there is evidence of much complexity, yet how little we understand about the content and purpose of each individual sound. (Whereas with human sounds, we fool ourselves into thinking that we do understand the content and purpose.) I will outline the ways in which we have developed machine listening methods adapted to specific aspects of bird vocalisation - its fine details and its temporal structure - and how the challenge relates to the wider field of machine listening.

Dan Stowell is a researcher in machine listening - which means using computation to understand sound signals. He co-leads the Machine Listening Lab at Queen Mary University of London, based in the Centre for Digital Music. Dan has worked on voice, music and environmental soundscapes, and is currently leading a five-year EPSRC fellowship project researching the automatic analysis of bird sounds. His first degree was from Cambridge University, and his PhD from Queen Mary University of London.



----

## <a name="location"></a>  LOCATION and DIRECTIONS
----

Sussex Humanities Lab, Silverstone SB211, Arts Road, Falmer, East Sussex, BN1 9RG

We are a short bus or train journey from the centre of Brighton and within easy reach of London via the Victoria and Thameslink lines and the major international airports at Gatwick and Heathrow.

Travel Directions can be found [here](http://www.sussex.ac.uk/about/directions)

The Sussex Humanities Lab is located in the School of Media, Film & Music, Silverstone Building which is situated in Arts Road, between Arts blocks B and C (number '16' on the [campus map](www.sussex.ac.uk/about/documents/campusmap.pdf)).

Participant accommodation is in central Brighton at the [Premiere Inn](http://www.premierinn.com/gb/en/hotels/england/east-sussex/brighton/brighton-city-centre.html). 144 North Street, Brighton, East Sussex BN1 1RE
