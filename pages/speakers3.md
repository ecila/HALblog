---
layout: page
title: "SCHEDULE"
header: no
image:
  title: "grays_lato_img.gif"

permalink: "/W3schedule&speakers/"
---

### Day 1
<p></p>

1030 : Tea/coffee     
1100 : Welcome & introduction Alice Eldridge & Paul Stapleton   
1115 : **Algorithmic Listening Project Updates**   
&nbsp;  _Algorithms that Matter_  - Hanns Holger Rutz   
&nbsp; _Systemic Improvisation_  - Palle Dahlstedt   

1300 : Lunch (in the Sussex Humanities Lab)   

1400 : **Oi, Algorithm! Chew On This! - Assaying the Noise Between Human and Algorithm**   
&nbsp; John Bowers & Owen Green   
1500 : Coffee   
1515 : **Adaptive & Reflexive Musical Listening Algorithms**   
&nbsp; _A sense of being ‘listened to'_  -- Tom Davis & Nick Ward   
&nbsp; _Self-listening play in generative music_  -- Ron Chrisley


1830 : Dinner at [The Rose Hill](http://www.therosehill.co.uk/)   

2030 : Long Table discussion on [Humanising Algorithmic Listening in Culture and Conservation](http://brightondigitalfestival.co.uk/events/humanising-algorithmic-listening-culture-conservation)   
2200 : Finish (latest)


### Day 2
<p></p>
1030 : **Audio feature surfing**   
&nbsp; _Introduction to CaTART_ - Diemo Schwarz   
&nbsp; _Getting to know big audio data_ - Alice Eldridge   
&nbsp; _Listening out for gender-based conversational dynamics_ - Ben Roberts   
1115 : Coffee   
1130 &nbsp; _Feature Hacking_ - all   
1330 : Lunch (foyer)  
1430 : **Listening with dynamical and chaotic systems**   
&nbsp; Marije Baalman & Chris Kiefer   
1630 : Coffee   
1645  Closing Panel - David Kant, Parag Mital, Simon Waters   
1745 : End   

... Dinner and drinks for those staying  

----
----
## SESSIONS
----
----

## Day 1
---

![image of HannsHolger]({{site.urlimg}}p_rutz.jpg)
### **Hanns Holger Rutz**
*Algorithms that Matter*
<p></p>


Algorithms that Matter (Almat) is a three-year FWF-funded artistic research project (AR 403) run by Hanns Holger Rutz and David Pirrò at the IEM Graz. It asks how algorithmic processes emerge and structure the praxis of experimental computer music. What we are interested in is to rethink algorithms as agents co-determining the boundary between an artistic machine or “apparatus” and the object produced through this machine. Unravelling the seemingly stable notion of algorithm, we look at the way an experimental culture in which the work with algorithms is embedded shapes our understanding of it, retroacts and changes the very praxis of composition and performance. Using as dispositifs two distinct software systems we have created, _SoundProcesses_ and _rattle_, we implement a series of connected experiments, addressing research questions such as: What are the “units” of algorithms, in what way can they be de- and recomposed, what is the nature of their affordances and material traces, how can they be preserved and inform the methodology of artistic research? Special focus is put on the reconfiguration of elements, such as relaying a system to another artist/composer, and we work with a number of invited guest artists to explore the different algorithmic strategies.   
[https://almat.iem.at/](https://almat.iem.at/)


<p></p>
---

![image of palle]({{site.urlimg}}w3_SI.png)
### **Palle Dahlstedt**
*Systemic Improvisation*
<p></p>

Palle will send me some text to put here very soon ...

<p></p>

---
![image of John Bowers]({{site.urlimg}}p_oi.png)
### **Oi, Algorithm! Chew On This! - Assaying the Noise Between Human and Algorithm**
*John Bowers & Owen Green*
<p></p>
We take the position that what it is to be human and what it is to be algorithmic can be creatively considered as variable affairs, complexly intertwined, co-indexical and so constitute a domain of investigation which is labile, uncertain and profoundly noisy. We propose to map some of this territory through a series of design provocations and a large portfolio of small collaborative makes, which are assembled in performance or installation, and critically reflected upon in the light of the concerns of the Network.

We will give a short performance-lecture, seguing into discussion that details the impetus and goals for our collaboration. 

<p></p>
---

### **Adaptive & Reflexive Musical Listening Algorithms**
In this session, participants will present plans for practice-based investigations into the potential for context sensitive, reflexive and / or adaptive listening processes.

![image of Nick Ward]({{site.urlimg}}p_ward.jpg)
**How can a sense of being ‘listened to’ affect human-algorithm listening relationships?**   
*Nicholas Ward & Tom Davis*   

<p></p>
Algorithms are used in a lot of different listening contexts, but they often have a reduced view of the world they are listening to. For example, features may be selected for them to recognise and respond to in order to create achievable classification exercises. In these scenarios, a lot of information regarding the wider context of the audio is lost. For example, in musical performance scenarios, listening algorithms can be used to modify systems in real-time based on audio input. These algorithms will respond identically given the same audio input irrespective of the performance context. Rather than create algorithms that perform the same in any context, can we make their listening context dependent, can we make their responses reflexive and relational?
<p></p>

![image of Ron]({{site.urlimg}}p_chrisley.jpg)
**What role might self-listening play in generative music systems?**   
*Ron Chrisley*
<p></p>
Although it may seem obvious that in order to create interesting music one must be capable of listening to music as music, the ability to listen is often omitted in the design of musical generative systems.  And for those few systems that can listen, the emphasis is almost exclusively on listening to others, e.g., for the purposes of interactive improvisation.  The project aims to explore the role that a system’s listening to, and evaluating, that system's own musical performance (as its own musical performance) can play in musical generative systems.  What kinds of aesthetic and creative possibilities are afforded by such a design? How does the role of self-listening change at different timescales? Can self-listening generative systems shed light on neglected aspects of human performance?  A three-component architecture for answering questions such as these will be presented.
<p></p>


---
---
## Day 2
---
---

### **Audio Feature Tweaking**
![image of Diemo]({{site.urlimg}}diemo_catart.png)
**Introduction to CataRT**
*Diemo Schwarz*

<p></p>
[http://imtr.ircam.fr/imtr/CataRT](http://imtr.ircam.fr/imtr/CataRT)
<p></p>

**Getting to Know Big Audio Data** -- *Alice Eldridge*
<p></p>

<p></p>

**Listening out for gender-based conversational dynamics** -- *Ben Roberts*
<p></p>

<p></p>

---
---

![image of attractor]({{site.urlimg}}attractor.png)
### **Listening with dynamical and chaotic systems**   
*Marije Baalman & Chris Kiefer*   
<p></p>
What makes dynamical systems different from other approaches to algorithmic listening, and what are the best uses of these algorithms?  We'll explore dynamical systems hands-on, by doing some processing of live sensor data, and discuss their efficacy and applications.
<p></p>
---
